---
title: "Data analysis for WP10"
author: "Patrizia Maier"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=F, cache=F}

library(tidyverse)
library(janitor)
library(gtsummary)
library(performance)
library(rstatix)
library(ggpubr)
library(WRS2)
# library(WRS) # alternative: # source("Rallfun-v40.txt") # for WRS
library(afex)
library(lme4)
library(nlme)
library(glmmTMB)
library(emmeans)
library(car)
library(DHARMa)
# install.packages('tinytex')
# tinytex::install_tinytex() # latex for pdf file creation

# set contrast coding
#options(contrasts=c(unordered="contr.sum", ordered="contr.poly"))

```


```{r load_data, include=F}
file_name <- "../WP10_data/WP10_results/wp10_navigation_data.RData"
load(file_name)
sm_orig <- sm_data 
rm(file_name)

file_name <- "../WP10_data/WP10_results/wp10_post_nav_data.RData"
load(file_name)
rm(file_name)
```


## Demographics 

Available navigation data 

```{r demo_1, echo=F, message=F, warning=F}
t1 <- sm_data %>% 
  filter(trial_num==1, session==1) %>% 
  select(group, sex) %>%
  tbl_summary(by=group,
              label=list(sex ~ "Gender"),
              statistic=list(all_categorical() ~ "{n}")) %>% 
  modify_header(label="Starmaze data",
                stat_by="**{level}** N = {n}") %>% 
  modify_footnote(everything() ~ NA)
t1
rm(t1)

# t1 %>%
#   as_flex_table() %>%
#   flextable::save_as_docx(path="TEST.docx")
```
 
Available post-navigation data 
 
```{r demo_2, echo=F, message=F, warning=F}
t2 <- pt_data %>% 
  filter(trial_num==1) %>% 
  select(group, sex) %>%
  tbl_summary(by=group,
              label=list(sex ~ "Gender"),
              statistic=list(all_categorical() ~ "{n}")) %>% 
  modify_header(label="Post-navigation data",
                stat_by="**{level}** N = {n}") %>% 
  modify_footnote(everything() ~ NA)
t2
rm(t2)
```


```{r stats_data}

## learning
data_l <- sm_data %>%
  filter(exclude_trial_matlab==0) %>% 
  filter(condition %in% c("main_learn")) %>% 
  mutate(trial_in_cond_f=factor(trial_in_cond),
         trial_in_cond_0=trial_in_cond-1,
         block_f=factor(block),
         block_0=block-1,
         goal_f=factor(goal_i),
         goal_identity_f=factor(goal_identity)) %>% 
  droplevels()

# box-cox transformation
bc_t <- MASS::boxcox(time ~ group, data=data_l)
lambda_t <- bc_t$x[which.max(bc_t$y)]
bc_p <- MASS::boxcox(path_distance ~ group, data=data_l)
lambda_p <- bc_p$x[which.max(bc_p$y)]
data_l <- data_l %>% 
  mutate(boxcox_time=((time^lambda_t-1)/lambda_t),
         boxcox_path=((path_distance^lambda_p-1)/lambda_p))
rm(bc_t, bc_p, lambda_t, lambda_p)

## probe 
data <- sm_data %>%
  filter(exclude_trial_matlab==0) %>% 
  filter(condition %in% c("allo_ret", "ego_ret")) %>% 
  droplevels()

# box-cox transformation
bc_t <- MASS::boxcox(time ~ group, data=data)
lambda_t <- bc_t$x[which.max(bc_t$y)]
bc_p <- MASS::boxcox(path_distance ~ group, data=data)
lambda_p <- bc_p$x[which.max(bc_p$y)]
data <- data %>% 
  mutate(boxcox_time=((time^lambda_t-1)/lambda_t),
         boxcox_path=((path_distance^lambda_p-1)/lambda_p))
rm(bc_t, bc_p, lambda_t, lambda_p)


## probe correct trials 
data_c <- data %>% 
  filter(correct_final_alley==1) %>% 
  droplevels()

# box-cox transformation
bc_f <- MASS::boxcox(final_distance ~ group, data=data_c)
lambda_f <- bc_f$x[which.max(bc_f$y)]
data <- data %>% 
  mutate(boxcox_fd=((final_distance^lambda_f-1)/lambda_f))
rm(bc_f, lambda_f)

```


### Navigation: Learning trials 

```{r stats_hist}

ggplot(data_l, aes(x=time)) +
  geom_histogram() +
  facet_wrap(~group)

ggplot(data_l, aes(x=path_distance)) +
  geom_histogram() +
  facet_wrap(~group)

ggplot(data_l, aes(x=zone_editdistance)) +
  geom_histogram() +
  facet_wrap(~group)

ggplot(data_l, aes(x=rotation_xyz)) +
  geom_histogram() +
  facet_wrap(~group)


# # check distribution
# qqp(data_l$time, "norm")
# qqp(data_l$time, "lnorm")
# gamma <- fitdistr(data_l$time, "gamma")
# qqp(data_l$time, "gamma", shape=gamma$estimate[[1]], rate=gamma$estimate[[2]])


# ggplot(data_l %>% filter(id < 12000), aes(x=trial_in_cond, y=time)) +
#   geom_point() +
#   scale_x_continuous(breaks=1:8) +
#   facet_wrap(~id)

```

```{r stats_learning_time}

## 1) gaussian 
lmer.red <- mixed(time ~ group*block_f*trial_in_cond_0 + 
                     (block_f|id), data=data_l, expand_re=T,
# lmer.red <- mixed(time ~ group*block_f*trial_in_cond_f + 
#                      (block_f|id), data=data_l, expand_re=T,
                   control=lmerControl(optimizer="bobyqa",
                                       optCtrl=list(maxfun=1e6)))
check_model(lmer.red$full_model, panel=F)
# model does converge but diagnostics bad


## 2) gaussian with log-transformed outcome: removed for clarity 


## 3) gaussian with boxcox-transformed outcome 
lmer.red_boxcox <- mixed(boxcox_time ~ group*block_f*trial_in_cond_0+ 
                            (block_f|id), data=data_l, expand_re=T,
                          control=lmerControl(optimizer="bobyqa",
                                              optCtrl=list(maxfun=1e6)))
check_model(lmer.red_boxcox$full_model, panel=F)
simulationOutput <- simulateResiduals(fittedModel=lmer.red_boxcox$full_model, 
                                      plot=F)
testResiduals(simulationOutput)
plotResiduals(simulationOutput)
testCategorical(simulationOutput, catPred=data_l$group)
testCategorical(simulationOutput, catPred=data_l$block_f)
testCategorical(simulationOutput, catPred=data_l$trial_in_cond_f)
# not a good fit: heteroscedasticity 

# trial as continuous for slopes
emtrends(lmer.red_boxcox, pairwise ~ group, var="trial_in_cond_0")
emtrends(lmer.red_boxcox, pairwise ~ block_f, var="trial_in_cond_0")
# # trial as factor for polynomial contrasts 
# emmeans(lmer.red_boxcox, pairwise ~ trial_in_cond_f | block_f, adjust="bonferroni")
# t <- emmeans(lmer.red_boxcox, "trial_in_cond_f"
# contrast(t, "poly")
# main effects
emmeans(lmer.red_boxcox, pairwise ~ group, adjust="bonferroni")


## 4) gaussian with log link: does not converge

## 5) gamma with identity link: does not converge

## 6) inverse gaussian with identity link: does not converge

## 7) robustlmm: does not work 


## 8) model non-homogenous variances with nlme
# set contrasts ?
lme.red <- lme(time ~ group*block_f*trial_in_cond_0,
                 random=~1+block_f  | id, 
                 data=data_l, method="REML")
plot(lme.red, resid(., type="p") ~ fitted(.) | group)
plot(lme.red, group ~ resid(., type="p"))
Anova(lme.red, type="III")
anova.lme(lme.red)

lme.red_hetvar1 <- lme(time ~ group*block_f*trial_in_cond_0,
                 random=~1+block_f | id,
                 weights=varIdent(form=~1 | group),
                 data=data_l, method="REML")
plot(lme.red_hetvar1, resid(., type="p") ~ fitted(.) | group)
plot(lme.red_hetvar1, group ~ resid(., type="p"))
Anova(lme.red_hetvar1, type="III") # which type???
anova.lme(lme.red_hetvar1)

# models get considerably better with boxcox + variance, effects seem the same 

# model comparison
anova(lme.red, lme.red_hetvar1)


# extract estimated variance 
lme.red_hetvar1.VC <- lme.red_hetvar1$modelStruct$varStruct %>%
  coef(unconstrained = FALSE, allCoef = TRUE) %>%
  enframe(name = "grp", value = "varStruct") %>%
  mutate(sigma         = lme.red_hetvar1$sigma) %>%
  mutate(StandardError = sigma * varStruct) %>%
  mutate(Variance      = StandardError ^ 2)


# post-test
emtrends(lme.red_hetvar1, pairwise ~ group, var="trial_in_cond_0", adjust="bonferroni")
emtrends(lme.red_hetvar1, pairwise ~ block_f, var="trial_in_cond_0", adjust="bonferroni")
emmeans(lme.red_hetvar1, pairwise ~ group | block_f, adjust="bonferroni", mode="satterthwaite")

# ## 9) comparison to standard tests: same effect 
# summary(aov(time ~ (group+block_0+trial_in_cond_0)^2, data=data_l))
# bwtrim(time ~ group*trial_in_cond_0, id=id, data=data_l, tr=0.2, nboot=2000)
# bwtrim(time ~ group*block_0, id=id, data=data_l, tr=0.2, nboot=2000)
# bwtrim(time ~ trial_in_cond_0*block_0, id=id, data=data_l, tr=0.2, nboot=2000)

```

```{r stats_learning_others}

### path distance

### path edit distance 

### rotation 

t <- data_l %>% 
  select(id, group, session, trial_num, goal_i, path_length, rotation_xyz, rotation_xy, rotation_z) %>% 
  mutate(goal_i=factor(goal_i),
         rotation_xyz_n=rotation_xyz/360,
         rotation_xy_n=rotation_xy/360,
         flag=rotation_xy>rotation_xyz)

ggplot(data=t, aes(x=path_length, y=rotation_xy, color=flag)) + geom_point() + facet_wrap(~goal_i)
ggplot(data=t, aes(x=path_length, y=rotation_xyz, color=flag)) + geom_point() + facet_wrap(~goal_i)
ggplot(data=t, aes(x=rotation_xyz, y=rotation_xy, color=flag)) + geom_point() + facet_wrap(~goal_i)
ggplot(data=t, aes(x=rotation_xyz_n/path_length)) + geom_histogram()
ggplot(data=t, aes(x=rotation_xy_n/path_length)) + geom_histogram()

```


### Navigation: Probe trials 

```{r stats_correct}

### correct final alley
# 1) full binomial model with random intercept, slope and correlations: does not converge 
mixed.full <- mixed(correct_final_alley ~ group*session*condition + sex + 
                      (session*condition|id), data=data, 
                    family=binomial(link="logit"), method="LRT",
                    control=glmerControl(optimizer="bobyqa",
                                         optCtrl=list(maxfun=1e6)))

# 2) full binomial model with random intercept and slope, no correlations: does converge
mixed.red <- mixed(correct_final_alley ~ group*session*condition + sex +
                     (session*condition||id), data=data, expand_re=T,
                   family=binomial(link="logit"), method="LRT",
                   control=glmerControl(optimizer="bobyqa",
                                        optCtrl=list(maxfun=1e6)))

# model check with DHARMa
simulationOutput <- simulateResiduals(fittedModel=mixed.red$full_model, plot=F)
testResiduals(simulationOutput) 
plotResiduals(simulationOutput) 
testCategorical(simulationOutput, catPred=data$group)
testCategorical(simulationOutput, catPred=data$session)
testCategorical(simulationOutput, catPred=data$condition)
# diagnostics: ok 

# post-test for fixed effects
afex_plot(mixed.red, "session", "group", "condition", id = "id",
          data_geom = ggbeeswarm::geom_quasirandom)

emmeans(mixed.red, pairwise ~ group, type="response", adjust="bonferroni")
emmeans(mixed.red, pairwise ~ session, type="response")
emmeans(mixed.red, pairwise ~ condition, type="response")

# TBD: add effect size for contrasts 
# emV <- emmeans(mixed.red, ~ condition)
# eff_size(emV, sigma=sigma(mixed.red$full_model), edf=df.residual(mixed.red$full_model))


### correct final alley during session 1 (learning only)

### change in correct final alley (aggregated data) over time 
data_prepost <- sm_data %>%
  filter(exclude_trial_matlab==0) %>%
  filter(condition %in% c("allo_ret", "ego_ret")) %>%
  select(id, group, session, trial_num, condition, correct_final_alley) %>%
  pivot_wider(id_cols=c(id, trial_num, group, condition),
              names_from=session,
              names_prefix="s_",
              values_from=correct_final_alley) %>%
  group_by(id, group, condition) %>%
  summarise_at(vars(s_1, s_2), mean, na.rm=T) %>% 
  mutate(change_diff=s_2-s_1,
         change_rel=s_2/s_1,
         change_reldiff=(s_2-s_1)/s_1) %>% 
  ungroup() %>% 
  droplevels()

# 1) robust ANOVA from WRS/WRS2 
# a) two-way with factors group and condition (issue: contrasts are weird, therefore one-way post-hoc!)
t2way(change_rel ~ group*condition, data=data_prepost, tr=0.2, nboot=2000)
t2way(change_reldiff ~ group*condition, data=data_prepost, tr=0.2, nboot=2000)

# b) one way with factor group for post-hoc evaluation of factor group
#t1way(change_rel ~ group, data=data_prepost, tr=0.2, alpha=0.05, nboot=2000, method="bonferroni")
lincon(change_rel ~ group, data=data_prepost, tr=0.2, alpha=0.05, nboot=2000, method="bonferroni")

#t1way(change_reldiff ~ group, data=data_prepost, tr=0.2, alpha=0.05, nboot=2000, method="bonferroni")
lincon(change_reldiff ~ group, data=data_prepost, tr=0.2, alpha=0.05, nboot=2000, method="bonferroni")

# 2) robust Kruskal-Wallis
kruskal.test(change_rel ~ group, data=data_prepost)
dunn_test(change_rel ~ group, data=data_prepost, p.adjust.method="bonferroni")

kruskal.test(change_reldiff ~ group, data=data_prepost)
dunn_test(change_reldiff ~ group, data=data_prepost, p.adjust.method="bonferroni")

```

```{r stats_finaldistance}

### final distance (TBD: drop na)
# 1) full gaussian model: does not converge 
lmer.full <- mixed(final_distance ~ group*session*condition + sex + 
                     (session*condition|id), data=data_c, 
                   control=lmerControl(optimizer="bobyqa",
                                       optCtrl=list(maxfun=1e6)))

# 2) full gaussian model with reduced random effects: does converge
lmer.red <- mixed(final_distance ~ group*session*condition + sex + 
                    (session|id), data=data_c, 
                  control=lmerControl(optimizer="bobyqa",
                                      optCtrl=list(maxfun=1e6)))
check_model(lmer.red$full_model, panel=F)
# diagnostics: bad

## 3) full gaussian model with log-transformed outcome and reduced random effects: does converge 
lmer.red_log <- mixed(log_fd ~ group*session*condition + sex + 
                        (session|id), data=data_c, 
                      control=lmerControl(optimizer="bobyqa",
                                          optCtrl=list(maxfun=1e6)))

check_model(lmer.red_log$full_model, panel=F)
# diagnostics 1: ok

simulationOutput <- simulateResiduals(fittedModel=lmer.red_log$full_model, plot=F)
testResiduals(simulationOutput)
plotResiduals(simulationOutput)
testCategorical(simulationOutput, catPred=data_c$group)
testCategorical(simulationOutput, catPred=data_c$session)
testCategorical(simulationOutput, catPred=data_c$condition)
# diagnostics 2: flags outlier and non-normality, but not heteroskedasticity: ok

# post-test for fixed effects
lmer.red_log$anova_table

afex_plot(lmer.red_log,  "session", "group", "condition", id = "id",
          data_geom = ggbeeswarm::geom_quasirandom)

emmeans(lmer.red_log, pairwise ~ group, adjust="bonferroni")
emmeans(lmer.red_log, pairwise ~ session)


### change in correct final alley (aggregated data) 
data_prepost <- data_c %>%
  select(id, group, session, trial_num, condition, final_distance) %>%
  pivot_wider(id_cols=c(id, trial_num, group, condition),
              names_from=session,
              names_prefix="s_",
              values_from=final_distance) %>%
  group_by(id, group, condition) %>%
  summarise_at(vars(s_1, s_2), mean, na.rm=T) %>% 
  mutate(change_diff=s_2-s_1,
         change_rel=s_2/s_1,
         change_reldiff=(s_2-s_1)/s_1) %>% 
  ungroup() %>% 
  drop_na()

# 1) robust ANOVA from WRS/WRS2 
# a) two-way with factors group and condition (issue: contrasts are weird, therefore one-way post-hoc!)
t2way(change_rel ~ group*condition, data=data_prepost, tr=0.2, nboot=2000)
t2way(change_reldiff ~ group*condition, data=data_prepost, tr=0.2, nboot=2000)

# 2) robust Kruskal-Wallis
kruskal.test(change_rel ~ group, data=data_prepost)
dunn_test(change_rel ~ group, data=data_prepost, p.adjust.method="bonferroni")

kruskal.test(change_reldiff ~ group, data=data_prepost)
dunn_test(change_reldiff ~ group, data=data_prepost, p.adjust.method="bonferroni")

```


```{r stats_strategy}

t <- data %>% 
  filter(condition=="allo_ret", session==1) %>% 
  drop_na(search_strategy_in_allo) %>% 
  mutate(search_strategy_2=fct_recode(search_strategy_in_allo, allo="direct_allo", 
                                      allo="detour_allo", ego="direct_ego", ego="detour_ego"))

table(t$search_strategy_2, t$group)
fisher.test(table(t$search_strategy_2, t$group), simulate.p.value=T)

```


### Post-navigation memory test

```{r stats_layout}

data <- pt_data %>% 
  filter(condition=="layout") %>% 
  drop_na(score)

fisher.test(table(data$score, data$group))
pairwise_fisher_test(table(data$score, data$group), p.adjust.method="bonferroni")

```

```{r stats_gmda}

data <- pt_data %>% 
  filter(condition=="position") %>% 
  drop_na(score)

### 1) ANOVA
anova_gmda <- aov(score ~ group*sex, data=data)
check_model(anova_gmda, panel=F) # diagnostics: not great
data %>% shapiro_test(score) # potentially non-normality
data %>% levene_test(score ~ group) # potentially heteroscedasticity 

summary(anova_gmda)
pairwise.t.test(data$score, data$group, p.adjust.method="bonferroni")
performance::r2(aov(score ~ group, data=data))


### 2) robust ANOVA (WSR2)
t1way(score ~ group, data=data, tr=0.2, nboot=2000)
lincon(score ~ group, data=data, tr=0.2, nboot=2000, method="bonferroni")
t2way(score ~ group + sex, data=data, tr=0.2, nboot=2000)


### 3) Kruskal-Wallis test 
kruskal.test(score ~ group, data=data)
dunn_test(score ~ group, data=data, p.adjust.method="bonferroni")

```

```{r stats_landmark}
data <- pt_data %>% 
  filter(condition=="landmarks") %>% 
  drop_na(score)

### 1) ANOVA
anova_lm <- aov(score ~ group*sex, data=data)
check_model(anova_gmda, panel=F) # diagnostics: not great
data %>% shapiro_test(score) # potentially non-normality
data %>% levene_test(score ~ group) # potentially heteroscedasticity 

summary(anova_lm)
pairwise.t.test(data$score, data$group, p.adjust.method="bonferroni")
performance::r2(aov(score ~ group, data=data))


### 2) robust ANOVA (WSR2)
t1way(score ~ group, data=data, tr=0.2, nboot=2000)
lincon(score ~ group, data=data, tr=0.2, nboot=2000, method="bonferroni")
t2way(score ~ group + sex, data=data, tr=0.2, nboot=2000)


### 3) Kruskal-Wallis test 
kruskal.test(score ~ group, data=data)
dunn_test(score ~ group, data=data, p.adjust.method="bonferroni")

```

```{r stats_goal}

data <- pt_data %>% 
  filter(condition=="goals")

### 1) ANOVA
anova_goal <- aov(score ~ group*sex, data=data)
check_model(anova_gmda, panel=F) # diagnostics: not great
data %>% shapiro_test(score) # potentially non-normality
data %>% levene_test(score ~ group) # potentially heteroscedasticity 

summary(anova_goal)
pairwise.t.test(data$score, data$group, p.adjust.method="bonferroni")
performance::r2(aov(score ~ group, data=data))


### 2) robust ANOVA (WSR2)
t1way(score ~ group, data=data, tr=0.2, nboot=2000)
lincon(score ~ group, data=data, tr=0.2, nboot=2000, method="bonferroni")
t2way(score ~ group + sex, data=data, tr=0.2, nboot=2000)


### 3) Kruskal-Wallis test 
kruskal.test(score ~ group, data=data)
dunn_test(score ~ group, data=data, p.adjust.method="bonferroni")

```