---
title: "Data analysis for WP10"
author: "Patrizia Maier"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=F, cache=F}

library(tidyverse)
library(janitor)
library(gtsummary)
library(performance)
library(rstatix)
library(ggpubr)
library(WRS2)
# library(WRS) # alternative: # source("Rallfun-v40.txt") # for WRS
library(afex)
library(lme4)
library(nlme)
# library(parameters)
# library(lavaSearch2)
library(emmeans)
library(car)
library(DHARMa)
# install.packages('tinytex')
# tinytex::install_tinytex() # latex for pdf file creation

# set contrast coding
options(contrasts=c(unordered="contr.sum", ordered="contr.poly"))
# options("contrasts")
# options(contrasts=c(unordered="contr.treatment", ordered="contr.poly"))

```


```{r load_data, include=F}
file_name <- "../WP10_data/WP10_results/wp10_navigation_data.RData"
load(file_name)
sm_orig <- sm_data 
rm(file_name)

file_name <- "../WP10_data/WP10_results/wp10_post_nav_data.RData"
load(file_name)
rm(file_name)
```


### Demographics 

##### Available navigation data 

```{r demo_1, echo=F, message=F, warning=F}
t1 <- sm_data %>% 
  filter(trial_num==1, session==1) %>% 
  select(group, sex) %>%
  tbl_summary(by=group,
              label=list(sex ~ "Gender"),
              statistic=list(all_categorical() ~ "{n}")) %>% 
  modify_header(label="Starmaze data",
                stat_by="**{level}** N = {n}") %>% 
  modify_footnote(everything() ~ NA)
t1
rm(t1)

# t1 %>%
#   as_flex_table() %>%
#   flextable::save_as_docx(path="TEST.docx")
```
 
##### Available post-navigation data 
 
```{r demo_2, echo=F, message=F, warning=F}
t2 <- pt_data %>% 
  filter(trial_num==4) %>% 
  select(group, sex) %>%
  tbl_summary(by=group,
              label=list(sex ~ "Gender"),
              statistic=list(all_categorical() ~ "{n}")) %>% 
  modify_header(label="Post-navigation data",
                stat_by="**{level}** N = {n}") %>% 
  modify_footnote(everything() ~ NA)
t2
rm(t2)
```


```{r stats_data}

## practise motor control
data_p <- sm_data %>%
  filter(condition %in% c("practise")) %>%  
  select(id, group, sex, time, path_length, velocity) %>% 
  droplevels()

## learning
data_l <- sm_data %>%
  filter(exclude_trial_matlab==0) %>% 
  filter(condition %in% c("main_learn")) %>% 
  mutate(trial_in_cond_f=factor(trial_in_cond),
         trial_in_cond_0=trial_in_cond-1,
         trial_in_cond_c=trial_in_cond-4.5,
         block_f=factor(block)) %>% 
  droplevels()

# # box-cox transformation
# bc_t <- MASS::boxcox(time ~ group, data=data_l)
# lambda_t <- bc_t$x[which.max(bc_t$y)]
# bc_p <- MASS::boxcox(path_distance ~ group, data=data_l)
# lambda_p <- bc_p$x[which.max(bc_p$y)]
# data_l <- data_l %>% 
#   mutate(boxcox_time=((time^lambda_t-1)/lambda_t),
#          boxcox_path=((path_distance^lambda_p-1)/lambda_p))
# rm(bc_t, bc_p, lambda_t, lambda_p)

## probe 
data <- sm_data %>%
  filter(exclude_trial_matlab==0) %>% 
  filter(condition %in% c("allo_ret", "ego_ret")) %>% 
  droplevels()

## probe correct trials 
data_c <- sm_data %>% 
  filter(exclude_trial_matlab==0) %>% 
  filter(condition %in% c("allo_ret", "ego_ret")) %>% 
  filter(correct_final_alley==1) %>% 
  droplevels()

```


### Navigation
#### Motor control trial 

```{r stats_motor_control}

# ::: METHOD: single value per person, therefore (robust) ANOVA ::: #

# time: GROUPS DIFFER SIGNIFICANTLY 
t1way(time ~ group, data=data_p, tr=0.2, alpha=0.05, nboot=1000)
lincon(time ~ group, data=data_p, tr=0.2, alpha=0.05,  nboot=1000, method="bonferroni") # default: hochberg

# path length: GROUPS DIFFER SIGNIFICANTLY
t1way(path_length ~ group, data=data_p, tr=0.2, alpha=0.05, nboot=1000)
lincon(path_length ~ group, data=data_p, tr=0.2, alpha=0.05,  nboot=1000, method="bonferroni")

# velocity: no differences 
t1way(velocity ~ group, data=data_p, tr=0.2, alpha=0.05, nboot=1000)
lincon(velocity ~ group, data=data_p, tr=0.2, alpha=0.05,  nboot=1000, method="bonferroni")

# ::: MEANING: during practise, the younger the participants, the longer they take to complete the trial and the more they deviate from an ideal path (i.e. difficulties with joystick motor control) --> include time, path length and/or velocity as covariate ::: #

```

#### Learning trials 

```{r stats_learning}

# ::: METHOD: per person 8 trials ? 3 blocks (= 24 trials) with continuous outcome, therefore lmm model ::: #
# watch out for convergence (stepwise reduction of random effects), normality of residuals, homoscedasticity and outliers # 

## -- time -- ##
# 1) standard lmer model 
# contrasts set to sum-coding by mixed
learn.time <- mixed(time ~ group*block_f*trial_in_cond_c + (block_f|id), 
                    data=data_l, expand_re=T,
                    control=lmerControl(optimizer="bobyqa", optCtrl=list(maxfun=1e6)))
# check model
simulationOutput <- simulateResiduals(fittedModel=learn.time$full_model, plot=F)
testResiduals(simulationOutput)
plotResiduals(simulationOutput)
testCategorical(simulationOutput, catPred=data_l$group)
# model diagnostics are bad


# 2) advanced lme model with variance estimation 
# contrasts set in beginning, check options("contrasts") if in doubt 
learn.time_base <- lme(time ~ group*block_f*trial_in_cond_c,
                         random=~1+block_f | id,
                         data=data_l, method="ML")
learn.time_var <- update(learn.time_base, weights=varIdent(form=~1 | group))
anova.lme(learn.time_base, learn.time_var) # type="marginal" ?

plot(learn.time_var, resid(., type="p") ~ fitted(.) | group)
plot(learn.time_var, group ~ resid(., type="p"))

## 3) advanced lme model with variance estimation and log-transformed outcome OR boxcox-transformed outcome
# contrasts set in beginning, check options("contrasts") if in doubt 
learn.time_var_log <- lme(log(time) ~ group*block_f*trial_in_cond_c,
                         random=~1+block_f | id, 
                         weights=varIdent(form=~1 | group),
                         data=data_l, method="ML")

plot(learn.time_var_log, resid(., type="p") ~ fitted(.) | group, abline=0)
plot(learn.time_var_log, group ~ resid(., type="p"))

# main effects & interactions  
anova.lme(learn.time_var_log, type="marginal", adjustSigma=T)

# post-hoc comparisons 
emtrends(learn.time_var_log, pairwise ~ block_f, var="trial_in_cond_c", adjust="bonferroni")
emmeans(learn.time_var_log, pairwise ~ group, type="response", adjust="bonferroni")

# # extract estimated variance
# variance <- learn.time_var_log$modelStruct$varStruct %>%
#   coef(unconstrained = FALSE, allCoef = TRUE) %>%
#   enframe(name = "grp", value = "varStruct") %>%
#   mutate(sigma         = learn.time_var_log$sigma) %>%
#   mutate(StandardError = sigma * varStruct) %>%
#   mutate(Variance      = StandardError ^ 2)


## -- path metric distance -- ##

## 1) standard lme model without variance estimation 
# contrasts set in beginning, check options("contrasts") if in doubt 
learn.path <- lme(path_distance ~ group*block_f*trial_in_cond_c,
                  random=~1+block_f | id, 
                  data=data_l, method="REML")
plot(learn.path, resid(., type="p") ~ fitted(.) | group)
plot(learn.path, group ~ resid(., type="p"))


## 2) advanced lme model wit variance estimation 
# contrasts set in beginning, check options("contrasts") if in doubt 
learn.path_hetvar <- lme(path_distance ~ group*block_f*trial_in_cond_c,
                  random=~1+block_f | id, 
                  weights=varIdent(form=~1 | group),
                  data=data_l, method="REML")
plot(learn.path_hetvar, resid(., type="p") ~ fitted(.) | group)
plot(learn.path_hetvar, group ~ resid(., type="p"))

anova(learn.path, learn.path_hetvar) # variance estimation improves model 


## 3) lme model wit variance estimation and log-transformed outcome OR boxcox-transformed outcome  
# contrasts set in beginning, check options("contrasts") if in doubt 
data_l <- data_l %>% 
  mutate(path_log=log(path_distance))

learn.path_hetvar_log <- lme(path_log ~ group*block_f*trial_in_cond_c,
                  random=~1+block_f | id, 
                  weights=varIdent(form=~1 | group),
                  data=data_l, method="REML")
plot(learn.path_hetvar_log, resid(., type="p") ~ fitted(.) | group)
plot(learn.path_hetvar_log, group ~ resid(., type="p"))


## -- path edit distance -- ##
## 1) standard lme model without variance estimation 
# contrasts set in beginning, check options("contrasts") if in doubt 
learn.path_ed <- lme(zone_editdistance ~ group*block_f*trial_in_cond_c,
                  random=~1+block_f | id, 
                  data=data_l, method="REML")
plot(learn.path_ed, resid(., type="p") ~ fitted(.) | group)
plot(learn.path_ed, group ~ resid(., type="p"))


## 2) advanced lme model wit variance estimation
# contrasts set in beginning, check options("contrasts") if in doubt 
learn.path_ed_hetvar <- lme(zone_editdistance ~ group*block_f*trial_in_cond_c,
                  random=~1+block_f | id, 
                  weights=varIdent(form=~1 | group),
                  data=data_l, method="REML")
plot(learn.path_ed_hetvar, resid(., type="p") ~ fitted(.) | group)
plot(learn.path_ed_hetvar, group ~ resid(., type="p"))

anova(learn.path_ed, learn.path_ed_hetvar) # variance estimation improves model 


## -- target metric distance -- ##

## -- (initial) rotation  -- ##


```

#### Probe trials 

```{r stats_probe_global_accuracy}

# ::: METHOD: per person several trials (session, condition) with binomial outcome, therefore glmm model ::: #
# watch out for convergence (stepwise reduction of random effects) # 

# -- correct final alley -- ##
# 1) full binomial model (with reduced random effects due to failed convergence)
probe.acc <- mixed(correct_final_alley ~ group*session*condition + sex + 
                     (session*condition||id), data=data, expand_re=T,
                   family=binomial(link="logit"), method="LRT",
                   control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=1e6)))

# check model
simulationOutput <- simulateResiduals(fittedModel=probe.acc$full_model, plot=F)
testResiduals(simulationOutput) 
plotResiduals(simulationOutput) 
testCategorical(simulationOutput, catPred=data$group)
testCategorical(simulationOutput, catPred=data$session)
testCategorical(simulationOutput, catPred=data$condition)
# diagnostics: ok 

# post-test for fixed effects
# TBD: add effect size calculation
afex_plot(probe.acc, "session", "group", "condition", id = "id",
          data_geom = ggbeeswarm::geom_quasirandom)

emmeans(probe.acc, pairwise ~ group, type="response", adjust="bonferroni")
emmeans(probe.acc, pairwise ~ session, type="response")
emmeans(probe.acc, pairwise ~ condition, type="response")

# ::: MEANING: Significant differences between age groups (the older, the better), sessions (s1 better than s2) and slight difference between conditions (ego slightly better than allo), no interactions. ::: # 

```

```{r stats_probe_global_accuracy_change}

# ::: METHOD: one aggregated value per person, therefore (robust) ANOVA ::: #  

# --- change calculation --- #
data_prepost <- sm_data %>%
  filter(exclude_trial_matlab==0) %>%
  filter(condition %in% c("allo_ret", "ego_ret")) %>%
  select(id, group, session, trial_num, condition, correct_final_alley) %>%
  pivot_wider(id_cols=c(id, trial_num, group, condition),
              names_from=session,
              names_prefix="s_",
              values_from=correct_final_alley) %>%
  group_by(id, group, condition) %>%
  summarise_at(vars(s_1, s_2), mean, na.rm=T) %>% 
  mutate(change_diff=s_2-s_1,
         change_rel=s_2/s_1,
         change_reldiff=(s_2-s_1)/s_1) %>% 
  ungroup() %>% 
  droplevels()


# --- change relative difference --- # 
# 1) standard ANOVA
# contrasts are set to sum by default
aov.change <- aov_car(change_reldiff ~ group*condition + Error(id/condition), data=data_prepost)
qqPlot(data_prepost$change_reldiff) # non-normality
data_prepost %>% shapiro_test(change_reldiff) 
plot(predict(aov.change), residuals(aov.change), main="Residuals vs. Predicted") # homoscedasticity ok
data_prepost %>% levene_test(change_reldiff ~ group) 
summary(aov.change)
emmeans(aov.change, pairwise ~ group | condition, adjust="bonferroni")


# 2) robust ANOVA from WRS/WRS2 
# contrasts are set to sum by default (I think)
# # robust mixed anova 
raov.change <- bwtrim(change_reldiff ~ group*condition, id=id, data=data_prepost, tr=0.2)
# # alternative to trim: mom-esitmator
# sppba(change_reldiff ~ group*condition, id=id, data=data_prepost, est="mom", avg=TRUE, nboot=500, MDIS=FALSE)
# sppbb(change_reldiff ~ group*condition, id=id, data=data_prepost, est="mom", avg=TRUE, nboot=500)
# sppbi(change_reldiff ~ group*condition, id=id, data=data_prepost, est="mom", avg=TRUE, nboot=500)
raov.change
# using one-way post-test lincon() because no dedicated post-test for bwtrim() 
lincon(change_reldiff ~ group, data=data_prepost, tr=0.2, alpha=0.05, method="bonferroni")


# ::: MEANING: Some evidence in favor of consolidation differences between children and adults. However, effect was found only in robust and not in standard ANOVA. There was also no significant group*session interaction in the previous analysis. Does this make sense? ::: #

```

```{r stats_probe_local_accuracy}

### A) final distance in correct trials 

### B) TBD Matlab: final distance in relation to local (alley) environment for all trials 

### change value or rather not? 

```

```{r stats_probe_metric}

## -- time -- ##

## -- path metric distance  -- ##

## -- path edit distance  -- ##

## -- target metric distance -- ##

## -- (initial) rotation  -- ##


### change values or rather not? 


```

```{r stats_probe_strategy}

```

```{r stats_probe_allo_strategy}

# TBD: change preprocessing in Matlab to make more inclusive 

data_allo_strategy <- data %>% 
  filter(condition=="allo_ret", session==1) %>% 
  drop_na(search_strategy_in_allo) %>% 
  mutate(search_strategy_2=fct_recode(search_strategy_in_allo, allo="direct_allo", 
                                      allo="detour_allo", ego="direct_ego", ego="detour_ego"))

table(data_allo_strategy$search_strategy_2, data_allo_strategy$group)

# option 1) fisher test: tests independence of rows and columns in a contingency table with fixed marginals.
fisher.test(table(data_allo_strategy$search_strategy_2, data_allo_strategy$group), simulate.p.value=T)

# option 2) discANOVA from WRS2: tests hypothesis that independent groups have identical multinomial distributions. 
discANOVA(search_strategy_2 ~ group, data=data_allo_strategy, nboot=500) 
discmcp(search_strategy_2 ~ group, data=data_allo_strategy, alpha=0.05, nboot=500)

# option 3) multinomial linear regression 


# ::: MEANING: xxx ::: #

```

```{r stats_probe_ego_strategy}

```


### Post-navigation memory test
#### Identifying the maze layout 

```{r stats_layout}

data <- pt_data %>% 
  filter(condition=="layout") %>% 
  drop_na(score)

# option 1) fisher test: tests independence of rows and columns in a contingency table with fixed marginals.
fisher.test(table(data$score, data$group))
pairwise_fisher_test(table(data$score, data$group), p.adjust.method="bonferroni")

# option 2) discANOVA from WRS2: tests hypothesis that independent groups have identical multinomial distributions. 
discANOVA(score ~ group, data=data, nboot=500)
discmcp(score ~ group, data=data, alpha=0.05, nboot=500) 

# ::: MEANING: significant differences between age groups in performance ::: #

```

#### Identifying the landmarks 

```{r stats_landmark}
data <- pt_data %>% 
  filter(condition=="landmarks") %>% 
  drop_na(score)

# option 1) standard ANOVA
aov.lm <- aov_car(score ~ group + Error(id), data=data)
qqPlot(data$score) # non-normality
data %>% shapiro_test(score) 
plot(predict(aov.lm), residuals(aov.lm), main="Residuals vs. Predicted") # homoscedasticity ok
data %>% levene_test(score ~ group) 
summary(aov.lm)
emmeans(aov.lm, pairwise ~ group, adjust="bonferroni")

# option 2) robust ANOVA (WSR2)
t1way(score ~ group, data=data, tr=0.2, nboot=1000)
lincon(score ~ group, data=data, tr=0.2, nboot=1000, method="bonferroni")

# ::: MEANING: no reliable, significant differences between age groups in performance ::: #

```

#### Identifying the relationships between landmarks and goals 

```{r stats_gmda}

data <- pt_data %>% 
  filter(condition=="position") %>% 
  drop_na(score)

# option 1) standard ANOVA
aov.gmda <- aov_car(score ~ group + Error(id), data=data)
qqPlot(data$score) # non-normality
data %>% shapiro_test(score) 
plot(predict(aov.gmda), residuals(aov.gmda), main="Residuals vs. Predicted") # heteroscedasticity
data %>% levene_test(score ~ group) 
summary(aov.gmda)
emmeans(aov.gmda, pairwise ~ group, adjust="bonferroni")

# option 2) robust ANOVA (WSR2)
t1way(score ~ group, data=data, tr=0.2, nboot=1000)
lincon(score ~ group, data=data, tr=0.2, nboot=1000, method="bonferroni")

# ::: MEANING: significant differences between children and adults in performance ::: #

```

```{r stats_gmda_explore}

# file_name <- "../WP10_data/WP10_results/wp10_GMDA_data_220505.Rdata"
# load(file_name)
# rm(file_name)

# # individual scores
# CanOrg <- data_gmda %>% filter(gmda_measure=="SQRT(CanOrg)")
# CanAcc <- data_gmda %>% filter(gmda_measure=="CanAcc")
# DistAcc <- data_gmda %>% filter(gmda_measure=="DistAcc")
# AngleAcc <- data_gmda %>% filter(gmda_measure=="AngleAcc")

# boxplot <- function(d){
#   ggplot(data=d, aes(x=group, y=score, fill=group)) +
#     geom_boxplot(outlier.shape=NA) +
#     geom_point()
# }

# boxplot(CanOrg)
# lincon(score ~ group, data=CanOrg, tr=0.2, nboot=1000, method="bonferroni")

# boxplot(CanAcc)
# lincon(score ~ group, data=CanAcc, tr=0.2, nboot=1000, method="bonferroni")

# boxplot(DistAcc)
# lincon(score ~ group, data=DistAcc, tr=0.2, nboot=1000, method="bonferroni")

# boxplot(AngleAcc)
# lincon(score ~ group, data=AngleAcc, tr=0.2, nboot=1000, method="bonferroni")

# # composite score
# GMDA <- data_gmda %>% filter(gmda_measure %in% c("SQRT(CanOrg)", "CanAcc", "DistAcc", "AngleAcc")) %>%
#   group_by(id, group) %>% summarise(score=mean(score))

# boxplot(GMDA)
# lincon(score ~ group, data=GMDA, tr=0.2, nboot=1000, method="bonferroni")

# rm(data_gmda, GMDA, CanOrg, CanAcc, DistAcc, AngleAcc, boxplot)

```